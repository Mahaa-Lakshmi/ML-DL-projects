# ğŸ§¾ FinExtractAI â€” Intelligent Invoice Information Extractor

FinExtractAI is a multi-agent, modular pipeline for automated information extraction from invoice images. It combines OCR, LLM-based semantic parsing, and validation logic to extract structured fields (seller, buyer, invoice number, date, amount, currency) from unstructured documents.

---

## ğŸ’¡ Features

- ğŸ§  **Multi-agent architecture** (modular, extensible design)
- ğŸ–¼ï¸ **OCR preprocessing** using Tesseract
- ğŸ” **Semantic entity extraction** with Gemini Flash & Mistral 7B
- âœ… **Validation agent** (date logic, currency conversion)
- ğŸ“¦ **SQLite database logging** of extracted fields
- ğŸ“Š **Visualization agent** overlays fields on images
- ğŸ” **A/B evaluation pipeline** for LLM performance


---

## ğŸ› ï¸ Agents Overview

| Agent                              | Responsibility                                 |
|-------------------------------------|------------------------------------------------|
| `OCRAgent`                         | Extracts text from invoice images (Tesseract)  |
| `SemanticEntityAgentWithGemini`     | Structured fields via Gemini Flash               |
| `SemanticEntityAgentWithMistral`    | Structured fields via Mistral 7B               |
| `ValidationAgent`                   | Validates dates, converts currency to INR      |
| `VisualizerAgent`                   | Draws bounding boxes on fields                 |
| `SQLiteAgent`                       | Stores results in SQLite DB                    |

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ agents.py                  # All core agents (OCR, LLMs, validation, etc.)
â”œâ”€â”€ pipeline.py                # Pipeline orchestrating the agents
â”œâ”€â”€ evaluate_ab.py             # Accuracy scoring for each field (Gemini vs Mistral)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ground_truth.csv
â”‚   â”œâ”€â”€ gemini_output_aggregated.csv
â”‚   â””â”€â”€ mistral_output_aggregated.csv
â”œâ”€â”€ visualizations/            # Saved annotated invoice images
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
â””â”€â”€ processing.ipynb            #Execution code Kaggle friendly

```

---

## ğŸ“ˆ Evaluation Metrics

- **Field-level accuracy:** Exact string match between predicted and ground truth values.
- **Other Evaluations:**  
  - Levenshtein distance (fuzzy string comparison) -  How many edits (insertions, deletions, substitutions) are needed to turn one string into another.  
  - F1 score evaluation  
  - Jaccard similarity

---

## ğŸ§ª Sample Output

```json
{
  "seller": "Lopez, Miller and Romero",
  "invoice_no": "802205",
  "invoice_date": "05/08/2007",
  "buyer": "Hayes LLC",
  "currency": "USD",
  "total": "534.11",
  "Total_in_INR": "43925.00"
}
```

---

## ğŸ”§ Setup & Usage

1. **Install requirements**
    ```sh
    pip install -r requirements.txt
    ```

2. **Set your API keys**
    - Google Gemini: `GEMINI_KEY`
    - Hugging Face: `HUGGINGFACE_API`

3. **Run the pipeline**
    ```sh
    streamlit run pipeline.py
    ```

4. **Evaluate accuracy**
    ```sh
    python evaluate_ab.py
    ```

---

## ğŸ§  What Weâ€™ll Learn / Demonstrate

- âœ… LLM orchestration for structured extraction
- âœ… Multi-agent design pattern for modular ML systems
- âœ… A/B evaluation of LLMs using field-level metrics
- âœ… OCR + NLP fusion for real-world document tasks
- âœ… Prompt engineering for few-shot examples
- âœ… Data validation & enrichment (e.g., currency conversion)
- âœ… Image annotation for debugging model predictions

---

**Happy extracting!**